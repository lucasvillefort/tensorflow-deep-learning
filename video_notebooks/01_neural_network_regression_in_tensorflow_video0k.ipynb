{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/video_notebooks/01_neural_network_regression_in_tensorflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKarSre47Ahv"
   },
   "source": [
    "# Introduction to Regression with Neural Networks in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number.\n",
    "\n",
    "See full course materials on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u8MsQmV7hDo",
    "outputId": "533835b3-7dc1-4297-a62e-9e54eeb9f9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IalXU1QB7spg"
   },
   "source": [
    "## Creating data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "YQZbzH4O70xl",
    "outputId": "202ae93a-8249-4c51-e6d9-f4d7b44027d0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clux4ncl8TJ8",
    "outputId": "64ac053c-d043-4c83-b78a-742df46938cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWmKUOWc8mdz"
   },
   "source": [
    "## Input and output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zmEIIElh8x1Z",
    "outputId": "d4b79a98-c51a-4f34-d7c7-50d558fe5f4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DExhPoos9gZF",
    "outputId": "07b79633-3eab-42ec-fe0d-250d3aa1eae1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nq-Pb-Z69jxp",
    "outputId": "86a25525-3cb9-4486-c328-327f359eab0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.0, 6.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-20V_X69OE0",
    "outputId": "e0cf92b4-aac0-4f74-ed65-f0ab87a3c41d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaOI4HU19bBJ",
    "outputId": "aa5f73a0-fa8c-4f31-d26b-b34a9b23ef40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYHpBCXQ93xD",
    "outputId": "7e4955b3-cf39-4acc-9e43-d59bfb81d728"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXXzG3aR97i7",
    "outputId": "9a13b136-34b4-4d85-aa1e-944694795646"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our NumPy arrays into tensors with dtype float32\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTUb3n6d_FrY",
    "outputId": "739df089-7f52-4860-ad06-3c82b6bb3df5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "NUB3rlwu_OZ5",
    "outputId": "0896d969-9a48-4d06-b335-39acd57a8d8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc24bd490b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu0RYMXr_VC-"
   },
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
    "2. **Compiling a model** - define the loss funtion (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. Fitting a model - letting the model try to find patterns between X & y (features and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9k5wWQe_aU3",
    "outputId": "10518f53-6280-4a57-e755-0d63500bb260"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc24b3ec780>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
    "              optimizer=tf.keras.optimizers.SGD(), # sgd is short for stochasitc gradient descent\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOkNe41hChw-",
    "outputId": "1996cbf3-5e00-4424-884f-4c95b4099c9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out X and y\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JBE5S-4DQFj",
    "outputId": "2a13f112-bae0-442d-f138-133a9e004948"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try and make a prediction using our model\n",
    "y_pred = model.predict([17.0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZm0x_e0DdvS",
    "outputId": "39a10efd-7023-430b-9622-e14646699649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23.71602]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred + 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RIo2cOiDrHC"
   },
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hideen layers, change the activation function of each layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ki4x75jCDwlu",
    "outputId": "d8678344-0e8b-43d4-fa4c-5c176114da06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2412 - mae: 7.2412\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9263 - mae: 6.9263\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc248df93c8>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild our model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model (this time we'll train for longer)\n",
    "model.fit(X, y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMa-jMl6ccRT",
    "outputId": "2bfa8fcb-581c-47c4-e372-4d007f057d65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_w1g_ZKc0K_",
    "outputId": "2f80f128-5867-4452-e90e-9576673ce37f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if our model's prediction has improved...\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8r7_kLzc932",
    "outputId": "30451e90-5651-4d71-a67b-7cf5cddd9176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.7682 - mae: 11.7682\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4150 - mae: 10.4150\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.7212 - mae: 9.7212\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.0104 - mae: 9.0104\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2778 - mae: 8.2778\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.5198 - mae: 7.5198\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9648 - mae: 6.9648\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0672 - mae: 7.0672\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3315 - mae: 7.3315\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4673 - mae: 7.4673\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5285 - mae: 7.5285\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.4011 - mae: 7.4011\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1923 - mae: 7.1923\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9575 - mae: 6.9575\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6953 - mae: 6.6953\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4127 - mae: 6.4127\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3048 - mae: 6.3048\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2575 - mae: 6.2575\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3982 - mae: 6.3982\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4551 - mae: 6.4551\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4000 - mae: 6.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2482 - mae: 6.2482\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.0105 - mae: 6.0105\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7876 - mae: 5.7876\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6809 - mae: 5.6809\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5715 - mae: 5.5715\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6122 - mae: 5.6122\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6074 - mae: 5.6074\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5541 - mae: 5.5541\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4568 - mae: 5.4568\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3199 - mae: 5.3199\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1477 - mae: 5.1477\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9442 - mae: 4.9442\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8239 - mae: 4.8239\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7389 - mae: 4.7389\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6657 - mae: 4.6657\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5846 - mae: 4.5846\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4027 - mae: 4.4027\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2653 - mae: 4.2653\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1212 - mae: 4.1212\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9702 - mae: 3.9702\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8272 - mae: 3.8272\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7041 - mae: 3.7041\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5320 - mae: 3.5320\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3664 - mae: 3.3664\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2116 - mae: 3.2116\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0463 - mae: 3.0463\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8705 - mae: 2.8705\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6840 - mae: 2.6840\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.4868 - mae: 2.4868\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2787 - mae: 2.2787\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0596 - mae: 2.0596\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8293 - mae: 1.8293\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5876 - mae: 1.5876\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3530 - mae: 1.3530\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0849 - mae: 1.0849\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8224 - mae: 0.8224\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - mae: 0.5467\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2758 - mae: 0.2758\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1354 - mae: 0.1354\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4494 - mae: 0.4494\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6498 - mae: 0.6498\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6216 - mae: 0.6216\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8036 - mae: 0.8036\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7995 - mae: 0.7995\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7409 - mae: 0.7409\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7806 - mae: 0.7806\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6305 - mae: 0.6305\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5556 - mae: 0.5556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4306 - mae: 0.4306\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2786 - mae: 0.2786\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1378 - mae: 0.1378\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1193 - mae: 0.1193\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2777 - mae: 0.2777\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3245 - mae: 0.3245\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4157 - mae: 0.4157\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4319 - mae: 0.4319\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3391 - mae: 0.3391\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2968 - mae: 0.2968\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2355 - mae: 0.2355\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1633 - mae: 0.1633\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1339 - mae: 0.1339\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1262 - mae: 0.1262\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1702 - mae: 0.1702\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2124 - mae: 0.2124\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2288 - mae: 0.2288\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1901 - mae: 0.1901\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1354 - mae: 0.1354\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1218 - mae: 0.1218\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0382 - mae: 0.0382\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2197 - mae: 0.2197\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2189 - mae: 0.2189\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1427 - mae: 0.1427\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1168 - mae: 0.1168\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2069 - mae: 0.2069\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1524 - mae: 0.1524\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2133 - mae: 0.2133\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2329 - mae: 0.2329\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0780 - mae: 0.0780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc247d0cc50>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if we can make another to improve our model\n",
    "\n",
    "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(50, activation=None),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=\"mae\",\n",
    "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAkq8adjeo2y",
    "outputId": "902c66fa-49f1-4fa3-d61e-811b3d45e002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remind ourselves of the data\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84Wym6W6e45i",
    "outputId": "e425d539-3934-405f-900c-23abab3aad5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.58353]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to make a prediction\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYOVI6lMe_KR"
   },
   "source": [
    "## Evaluting a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building neural networks is:\n",
    "\n",
    "```\n",
    "Build a model  -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usrqoYOojh5S"
   },
   "source": [
    "When it comes to evaluation... there are 3 words you should memorize:\n",
    "\n",
    "> \"Visualize, visualize, visualize\"\n",
    "\n",
    "It's a good idea to visualize:\n",
    "* The data - what data are we working with? What does it look like?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original labels)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zcYJzAykVku",
    "outputId": "0b17b5a5-04c4-4743-a960-85c0d8f526ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYmBjJyGkyhf",
    "outputId": "dbfe5016-d05e-46a2-8a4b-188844f21224"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "GsPCWn6Bk7-n",
    "outputId": "be61290d-86df-4855-afc0-dfd0c03f1127"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc246399550>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYSYiP6mlE-g"
   },
   "source": [
    "### The 3 sets...\n",
    "\n",
    "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available.\n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
    "* **Test set** - the model gets evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6x4ayTkmbsz",
    "outputId": "d74dd6c9-d8ca-4f90-8553-d8a850464cbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSFQQTirmyvV",
    "outputId": "dab0f378-11bf-42d9-b9e0-1a8a727f0063"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40] # first 40 are training samples (80% of the data) \n",
    "y_train = y[:40]\n",
    "\n",
    "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
    "y_test = y[40:]\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TppBKDWnbKC"
   },
   "source": [
    "### Visualizing the data\n",
    "\n",
    "Now we've got our data in training and test sets... let's visualize it again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "Wx8g6vh9nwLs",
    "outputId": "e2c1369b-a186-4756-8b60-5afc26ee5cd2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "# Plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\") # our model will learn on this\n",
    "# Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\") # want our model to be able to predict this (given X, what's y?)\n",
    "# Show a legend\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0U3nhHtpKve"
   },
   "outputs": [],
   "source": [
    "# Let's have a look at how to build a neural network for our data\n",
    "\n",
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1)                             \n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])\n",
    "\n",
    "# # 3. Fit the model\n",
    "# model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnscI3h_qP5a"
   },
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "gfiOkjp5qSiZ",
    "outputId": "2c20dea6-5adb-47e9-c751-18174d65fd41"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b2QjQhzq6Ah",
    "outputId": "1d766f99-86b7-4d07-e197-29c116459a82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzPTRyrCqVpT"
   },
   "outputs": [],
   "source": [
    "# Let's create a model which builds automatically by defining the input_shape argument in the first layer\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model (same as above)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n",
    "  tf.keras.layers.Dense(1, name=\"output_layer\")\n",
    "], name=\"model_1\")\n",
    "\n",
    "# 2. Compile the model (same as above)\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_RDh-9PdrMXo",
    "outputId": "89fb981b-de9c-47ce-a55f-bc4c35ef2cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8BlRom8rhQx"
   },
   "source": [
    "* Total params - total number of parameters in the model.\n",
    "* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n",
    "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learn patterns or parameters from other models during **transfer learning**).\n",
    "\n",
    "📖 **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out [MIT's introduction to deep learning video](https://youtu.be/njKP3FqW3Sk). \n",
    "\n",
    "🛠 **Exercise:** Try playing around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZP91lGTgrPno",
    "outputId": "b589c1c7-d45f-445e-de99-d6b5c073421b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2462ffcf8>"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SS4oIHfktlex",
    "outputId": "c5e1e1a6-fa1c-4133-dea7-352aee602e86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary of our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "--yP4uW8ugKH",
    "outputId": "98e3fa2c-e85e-4474-9052-a3b94b7f4eb5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model=model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORwPibL8u7Yk"
   },
   "source": [
    "### Visualizing our model's predictions\n",
    "\n",
    "To visualize predictions, it's a good idea to plot them against the ground truth labels.\n",
    "\n",
    "Often you'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus your model's predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85dQbIrHsggD",
    "outputId": "2e596849-b9e8-46ab-a170-5c3d7295601e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.55218 ],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72763 ],\n",
       "       [ 84.31535 ],\n",
       "       [ 88.903076],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07853 ],\n",
       "       [102.66625 ],\n",
       "       [107.253975],\n",
       "       [111.8417  ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make some predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iw7TyglVtUZL",
    "outputId": "7ae9c816-6bea-4752-f3fd-59492f3c398d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZvNFJGVtjov"
   },
   "source": [
    "🔑 **Note:** If you feel like you're going to reuse some kind of functionality in the future, it's a good idea to turn it into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJsnIciYtWfn"
   },
   "outputs": [],
   "source": [
    "# Let's create a plotting function\n",
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     predictions=y_pred):\n",
    "  \"\"\"\n",
    "  Plots training data, test data and compares predictions to ground truth labels.\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(10, 7))\n",
    "  # Plot training data in blue\n",
    "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "  # Plot testing data in green\n",
    "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "  # Plot model's predictions in red\n",
    "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
    "  # Show the legend\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "6VeRueShuhfN",
    "outputId": "e9173e6e-9a31-4ed1-fb42-01b7760a86d3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(train_data=X_train,\n",
    "                 train_labels=y_train,\n",
    "                 test_data=X_test,\n",
    "                 test_labels=y_test,\n",
    "                 predictions=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poOuTGosukJU"
   },
   "source": [
    "### Evaluting our model's predictions with regression evaluation metrics\n",
    "\n",
    "Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n",
    "\n",
    "Since we're working on a regression, two of the main metrics: \n",
    "* MAE - mean absolute error, \"on average, how wrong is each of my model's predictions\"\n",
    "* MSE - mean square error, \"square the average errors\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmeohFOJu_C_",
    "outputId": "5b7f591f-2a4f-46a5-de64-48f98b6b4dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 3.1969 - mae: 3.1969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1969451904296875, 3.1969451904296875]"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model on the test\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eWAP6TCJyUeL",
    "outputId": "684aff9d-2b76-4eb1-b8e9-63319f75803b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
       "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, \n",
    "                                     y_pred=tf.constant(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znxoDzBCyGEd",
    "outputId": "585396a1-f7bc-46d4-9694-ab3665e8c9db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 70.55218 ],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72763 ],\n",
       "       [ 84.31535 ],\n",
       "       [ 88.903076],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07853 ],\n",
       "       [102.66625 ],\n",
       "       [107.253975],\n",
       "       [111.8417  ]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NB5OwjD2ySv4",
    "outputId": "e72a8b29-fcc8-4c37-ceec-824cb3cc34a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fit8MiNSyTZu",
    "outputId": "c9c2bbc2-083c-4fc9-8b6d-f5261b27e08f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([ 70.55218 ,  75.13991 ,  79.72763 ,  84.31535 ,  88.903076,\n",
       "        93.49081 ,  98.07853 , 102.66625 , 107.253975, 111.8417  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nFhtsK8J1j2M",
    "outputId": "8c0d3583-317e-4cbd-cdd8-2bf0642cb10a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test,\n",
    "                                     y_pred=tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BK4bRMgi4LcR",
    "outputId": "c83c22f5-b511-4e01-e487-9cd2767dafa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.070143>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean square error\n",
    "mse = tf.metrics.mean_squared_error(y_true=y_test,\n",
    "                                    y_pred=tf.squeeze(y_pred))\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h46VZYQ28tFP"
   },
   "outputs": [],
   "source": [
    "# Make some functions to reuse MAE and MSE\n",
    "def mae(y_true, y_pred):\n",
    "  return tf.metrics.mean_absolute_error(y_true=y_true,\n",
    "                                        y_pred=tf.squeeze(y_pred))\n",
    "  \n",
    "def mse(y_true, y_pred):\n",
    "  return tf.metrics.mean_squared_error(y_true=y_true,\n",
    "                                       y_pred=tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4mlm41z9w6S"
   },
   "source": [
    "## Running experiments to improve our model\n",
    "\n",
    "```\n",
    "Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it ...\n",
    "```\n",
    "\n",
    "1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
    "2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
    "3. Train for longer - give your model more of a chance to find patterns in the data.\n",
    "\n",
    "Let's do 3 modelling experiments:\n",
    "\n",
    "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs\n",
    "2. `model_2` - 2 layers, trained for 100 epochs\n",
    "3. `model_3` - 2 layers, trained for 500 epochs \n",
    "\n",
    "**Build `model_1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cLyuLdP-SIw",
    "outputId": "f6654942-3d40-4dd9-a904-38c13afadfc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1074 - mae: 11.1074\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2991 - mae: 9.2991\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2047 - mae: 12.2047\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4355 - mae: 11.4355\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc24a1876d8>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "9Wfj4dqK-z6H",
    "outputId": "08cde110-5b47-4b66-a693-36cf7014656a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc24b39abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions for model_1\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7B2ujgQeALRb",
    "outputId": "158e2db2-bc89-41e4-f0bf-b21cbeabe600"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_1 evaluation metrics\n",
    "mae_1 = mae(y_test, y_preds_1)\n",
    "mse_1 = mse(y_test, y_preds_1)\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMKAg48cAcAX"
   },
   "source": [
    "**Build `model_2`**\n",
    "\n",
    "* 2 dense layers, trained for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfNxa4oOBK55",
    "outputId": "e521be02-8a0f-4694-b371-89a61dc9c486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.4058 - mse: 1084.1482\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.6339 - mse: 777.9203\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.8935 - mse: 1334.8956\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.4055 - mse: 1106.8035\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9463 - mse: 281.1077\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8819 - mse: 168.6621\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1988 - mse: 151.3508\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0910 - mse: 160.3745\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 40.4763 - mse: 2586.0090\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.8688 - mse: 1094.4384\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2473 - mse: 147.9359\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.2803 - mse: 890.3867\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.9897 - mse: 399.9677\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.9217 - mse: 1049.5515\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9948 - mse: 450.2580\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3510 - mse: 80.6206\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8636 - mse: 174.7868\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5304 - mse: 565.8053\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3469 - mse: 167.7749\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6985 - mse: 455.7097\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.8985 - mse: 347.1929\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.1991 - mse: 285.1767\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7720 - mse: 91.7852\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0570 - mse: 153.7430\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.6838 - mse: 233.2949\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.1877 - mse: 1024.6091\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7432 - mse: 194.8454\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.8730 - mse: 835.6073\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2459 - mse: 96.7786\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.2641 - mse: 1535.1349\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 53.0225 - mse: 5030.2983\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9951 - mse: 211.7025\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6357 - mse: 337.3666\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6925 - mse: 214.4823\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2398 - mse: 92.9126\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6497 - mse: 403.6573\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0382 - mse: 192.3919\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1634 - mse: 433.6717\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.1013 - mse: 529.6439\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.4324 - mse: 610.1324\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9102 - mse: 279.6183\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2809 - mse: 186.6180\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7333 - mse: 167.0952\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.0260 - mse: 830.4244\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3897 - mse: 128.9549\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7904 - mse: 181.9212\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mse: 153.8708\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.2335 - mse: 402.8494\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5729 - mse: 99.8337\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8185 - mse: 260.3671\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5958 - mse: 154.7956\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.5538 - mse: 1613.0886\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.3541 - mse: 302.5293\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.9713 - mse: 859.3983\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.1938 - mse: 805.5451\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8837 - mse: 170.9834\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7445 - mse: 198.7015\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5995 - mse: 102.5891\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5172 - mse: 216.3367\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3200 - mse: 208.6371\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4604 - mse: 428.6393\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6052 - mse: 136.9777\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.4893 - mse: 152.4555\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.8450 - mse: 911.7511\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6761 - mse: 142.7374\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.7809 - mse: 704.4491\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7136 - mse: 136.0194\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6397 - mse: 149.2300\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 22.6914 - mse: 742.1761\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3316 - mse: 166.1628\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4355 - mse: 323.0843\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7437 - mse: 67.0210\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6891 - mse: 183.7296\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.0400 - mse: 908.8993\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5896 - mse: 149.3948\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4371 - mse: 188.3310\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6489 - mse: 429.2708\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0614 - mse: 95.4870\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.9675 - mse: 864.0864\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.7463 - mse: 1104.4036\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6714 - mse: 170.7055\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.0228 - mse: 211.9191\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4218 - mse: 395.5589\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2629 - mse: 73.0935\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9650 - mse: 312.8361\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2862 - mse: 315.3605\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.1086 - mse: 521.2534\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.8229 - mse: 1287.1907\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1742 - mse: 124.1342\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5240 - mse: 663.8612\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5716 - mse: 161.7467\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3977 - mse: 464.1326\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.4138 - mse: 81.9820\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7380 - mse: 445.7379\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1144 - mse: 164.0820\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.4346 - mse: 510.5842\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.1593 - mse: 209.9755\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5653 - mse: 169.4052\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8827 - mse: 265.4630\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.2277 - mse: 608.8218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2523e0358>"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "RW1hakVSCOUg",
    "outputId": "f4907b84-4bf0-4590-cea4-2ddb0c356b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc24aa90488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot predictions of model_2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgQMdpCICc9Q",
    "outputId": "261d2e57-a678-4df0-c75a-72bf14520df6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=13.070143>)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_2 evaluation metrics\n",
    "mae_2 = mae(y_test, y_preds_2)\n",
    "mse_2 = mse(y_test, y_preds_2)\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frsg7iYgCvo8"
   },
   "source": [
    "**Build `model_3`**\n",
    "\n",
    "* 2 layers, trained for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sfbKhNdDCXn",
    "outputId": "971cde3c-30d4-4359-a2fe-f32035429225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.8688 - mae: 27.8688\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 53.0225 - mae: 53.0225\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5896 - mae: 9.5896\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6489 - mae: 16.6489\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.7463 - mae: 26.7463\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.8229 - mae: 29.8229\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.2277 - mae: 20.2277\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.4479 - mae: 11.4479\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.4842 - mae: 17.4842\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0217 - mae: 7.0217\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5789 - mae: 23.5789\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.8932 - mae: 16.8932\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2954 - mae: 9.2954\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.3749 - mae: 25.3749\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.4621 - mae: 13.4621\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 14.5987 - mae: 14.5987\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5670 - mae: 9.5670\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 17.8092 - mae: 17.8092\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.1782 - mae: 17.1782\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.1182 - mae: 11.1182\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.3071 - mae: 23.3071\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6144 - mae: 9.6144\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 10.6899 - mae: 10.6899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.0355 - mae: 8.0355\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.6859 - mae: 29.6859\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0714 - mae: 8.0714\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.3086 - mae: 28.3086\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 32.9014 - mae: 32.9014\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.6291 - mae: 19.6291\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.0095 - mae: 7.0095\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8056 - mae: 21.8056\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9812 - mae: 7.9812\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.0585 - mae: 21.0585\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.0107 - mae: 9.0107\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.0502 - mae: 24.0502\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7537 - mae: 9.7537\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3052 - mae: 18.3052\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5833 - mae: 7.5833\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.5755 - mae: 18.5755\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5360 - mae: 10.5360\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.2694 - mae: 18.2694\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.1658 - mae: 23.1658\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.1362 - mae: 9.1362\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9181 - mae: 8.9181\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4732 - mae: 16.4732\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 8.4208 - mae: 8.4208\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36.9540 - mae: 36.9540\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.5820 - mae: 25.5820\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5392 - mae: 9.5392\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 26.6058 - mae: 26.6058\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7248 - mae: 8.7248\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.6172 - mae: 15.6172\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3065 - mae: 18.3065\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1994 - mae: 8.1994\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4964 - mae: 7.4964\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3374 - mae: 18.3374\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2895 - mae: 10.2895\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.6425 - mae: 29.6425\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.4537 - mae: 15.4537\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.0174 - mae: 17.0174\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 32.8218 - mae: 32.8218\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7038 - mae: 10.7038\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9054 - mae: 8.9054\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.1321 - mae: 22.1321\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.7113 - mae: 11.7113\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5734 - mae: 21.5734\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.2485 - mae: 19.2485\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0156 - mae: 11.0156\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6187 - mae: 9.6187\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.5908 - mae: 21.5908\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.2851 - mae: 26.2851\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8525 - mae: 9.8525\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.5630 - mae: 22.5630\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.1499 - mae: 10.1499\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.0464 - mae: 18.0464\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.8377 - mae: 28.8377\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.5279 - mae: 16.5279\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 11.2115 - mae: 11.2115\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.5839 - mae: 27.5839\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.2680 - mae: 8.2680\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2580 - mae: 9.2580\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.1440 - mae: 18.1440\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5995 - mae: 10.5995\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8992 - mae: 7.8992\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.4015 - mae: 17.4015\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0089 - mae: 11.0089\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7027 - mae: 11.7027\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.4062 - mae: 30.4062\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5557 - mae: 7.5557\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9905 - mae: 15.9905\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.5579 - mae: 8.5579\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.7339 - mae: 28.7339\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1689 - mae: 13.1689\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3101 - mae: 18.3101\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7376 - mae: 13.7376\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7104 - mae: 13.7104\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.5842 - mae: 28.5842\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0707 - mae: 7.0707\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0550 - mae: 7.0550\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.0067 - mae: 22.0067\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.8443 - mae: 20.8443\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4713 - mae: 12.4713\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9099 - mae: 17.9099\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7494 - mae: 13.7494\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7006 - mae: 13.7006\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4142 - mae: 9.4142\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.9796 - mae: 20.9796\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.5470 - mae: 9.5470\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.7256 - mae: 11.7256\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.3772 - mae: 14.3772\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8579 - mae: 14.8579\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9706 - mae: 14.9706\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.8998 - mae: 17.8998\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8327 - mae: 9.8327\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.3352 - mae: 18.3352\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0383 - mae: 15.0383\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.5874 - mae: 14.5874\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.3015 - mae: 23.3015\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3613 - mae: 13.3613\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.8517 - mae: 9.8517\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.5451 - mae: 12.5451\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1130 - mae: 7.1130\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 35.4567 - mae: 35.4567\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.8634 - mae: 34.8634\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9846 - mae: 7.9846\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.7004 - mae: 14.7004\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.7196 - mae: 16.7196\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.9329 - mae: 15.9329\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.1644 - mae: 16.1644\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.9324 - mae: 13.9324\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.0504 - mae: 18.0504\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.6120 - mae: 15.6120\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.2041 - mae: 21.2041\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.2732 - mae: 25.2732\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3176 - mae: 16.3176\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2729 - mae: 7.2729\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.9688 - mae: 16.9688\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1225 - mae: 7.1225\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2058 - mae: 9.2058\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.0961 - mae: 8.0961\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.0538 - mae: 17.0538\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8627 - mae: 8.8627\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7886 - mae: 8.7886\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.8161 - mae: 18.8161\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.0531 - mae: 14.0531\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.6831 - mae: 14.6831\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 15.8045 - mae: 15.8045\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.6810 - mae: 17.6810\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.2367 - mae: 13.2367\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.5070 - mae: 14.5070\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 23.2322 - mae: 23.2322\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3009 - mae: 9.3009\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36.6569 - mae: 36.6569\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.8205 - mae: 21.8205\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.2792 - mae: 7.2792\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.7127 - mae: 24.7127\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4220 - mae: 12.4220\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.5823 - mae: 10.5823\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.4883 - mae: 14.4883\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.6132 - mae: 8.6132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 43.0580 - mae: 43.0580\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 18.4611 - mae: 18.4611\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.8820 - mae: 6.8820\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7211 - mae: 13.7211\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.0154 - mae: 21.0154\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.3731 - mae: 19.3731\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4735 - mae: 11.4735\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5302 - mae: 7.5302\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.6453 - mae: 21.6453\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.1785 - mae: 33.1785\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0833 - mae: 10.0833\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.1012 - mae: 12.1012\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.1372 - mae: 26.1372\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.1751 - mae: 12.1751\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3272 - mae: 13.3272\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.3775 - mae: 29.3775\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.3329 - mae: 7.3329\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.1362 - mae: 31.1362\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.3015 - mae: 12.3015\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4103 - mae: 16.4103\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.9118 - mae: 21.9118\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.1501 - mae: 22.1501\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.7429 - mae: 7.7429\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1429 - mae: 8.1429\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.9435 - mae: 24.9435\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6958 - mae: 13.6958\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8926 - mae: 6.8926\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.5352 - mae: 24.5352\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.1721 - mae: 20.1721\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.9658 - mae: 11.9658\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.5391 - mae: 16.5391\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.8017 - mae: 16.8017\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2710 - mae: 15.2710\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.7179 - mae: 22.7179\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9234 - mae: 17.9234\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.1743 - mae: 6.1743\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.9440 - mae: 10.9440\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.1530 - mae: 23.1530\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.7331 - mae: 17.7331\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.9824 - mae: 6.9824\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.1857 - mae: 25.1857\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.9025 - mae: 8.9025\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.7668 - mae: 17.7668\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0002 - mae: 11.0002\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9191 - mae: 12.9191\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.6094 - mae: 13.6094\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4404 - mae: 7.4404\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7099 - mae: 10.7099\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2814 - mae: 13.2814\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.9763 - mae: 29.9763\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6304 - mae: 7.6304\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.9106 - mae: 9.9106\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 23.7669 - mae: 23.7669\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3937 - mae: 16.3937\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 21.0758 - mae: 21.0758\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.9367 - mae: 7.9367\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9731 - mae: 17.9731\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2375 - mae: 10.2375\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3338 - mae: 8.3338\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.0621 - mae: 5.0621\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5109 - mae: 23.5109\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.8309 - mae: 6.8309\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3863 - mae: 16.3863\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.5019 - mae: 7.5019\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.0573 - mae: 20.0573\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.7661 - mae: 13.7661\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.8282 - mae: 16.8282\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0514 - mae: 7.0514\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.4846 - mae: 21.4846\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.2880 - mae: 12.2880\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.8117 - mae: 11.8117\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3600 - mae: 8.3600\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.4833 - mae: 12.4833\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.2171 - mae: 32.2171\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4477 - mae: 10.4477\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.6832 - mae: 19.6832\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 35.0762 - mae: 35.0762\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.4192 - mae: 10.4192\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.7625 - mae: 9.7625\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.9500 - mae: 11.9500\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.3943 - mae: 9.3943\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 5.6071 - mae: 5.6071\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 37.4876 - mae: 37.4876\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.8830 - mae: 16.8830\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.8748 - mae: 12.8748\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.1960 - mae: 8.1960\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.5568 - mae: 13.5568\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4354 - mae: 15.4354\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.9626 - mae: 32.9626\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.2040 - mae: 14.2040\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.9196 - mae: 15.9196\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.0878 - mae: 19.0878\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 34.1178 - mae: 34.1178\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6798 - mae: 7.6798\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.2287 - mae: 25.2287\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 22.6759 - mae: 22.6759\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.8765 - mae: 8.8765\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.4709 - mae: 21.4709\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.6073 - mae: 20.6073\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.0611 - mae: 7.0611\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 25.8117 - mae: 25.8117\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 32.2247 - mae: 32.2247\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.0204 - mae: 10.0204\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 30.4171 - mae: 30.4171\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5020 - mae: 10.5020\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9909 - mae: 14.9909\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.6580 - mae: 14.6580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.3672 - mae: 23.3672\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1025 - mae: 13.1025\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2586 - mae: 9.2586\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.0041 - mae: 13.0041\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8863 - mae: 14.8863\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.7932 - mae: 14.7932\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.2751 - mae: 16.2751\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.8307 - mae: 20.8307\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 33.5318 - mae: 33.5318\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.2166 - mae: 8.2166\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.0960 - mae: 13.0960\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.3999 - mae: 8.3999\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1283 - mae: 7.1283\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.9390 - mae: 10.9390\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 19.7654 - mae: 19.7654\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 24.8625 - mae: 24.8625\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7422 - mae: 8.7422\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.9488 - mae: 5.9488\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.4400 - mae: 24.4400\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.9771 - mae: 5.9771\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.3250 - mae: 16.3250\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.0917 - mae: 6.0917\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9601 - mae: 14.9601\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6462 - mae: 7.6462\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 8.7654 - mae: 8.7654\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.5991 - mae: 14.5991\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.3166 - mae: 11.3166\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.9080 - mae: 21.9080\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8653 - mae: 14.8653\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.4970 - mae: 8.4970\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.3957 - mae: 10.3957\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.2556 - mae: 10.2556\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.3392 - mae: 6.3392\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4602 - mae: 17.4602\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4627 - mae: 11.4627\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.7294 - mae: 20.7294\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.3338 - mae: 31.3338\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 9.2542 - mae: 9.2542\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.8621 - mae: 14.8621\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.7182 - mae: 21.7182\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6615 - mae: 12.6615\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.0687 - mae: 6.0687\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2201 - mae: 13.2201\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 27.4244 - mae: 27.4244\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6407 - mae: 10.6407\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8230 - mae: 12.8230\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.8836 - mae: 15.8836\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 24.7510 - mae: 24.7510\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.3753 - mae: 17.3753\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.8241 - mae: 7.8241\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 25.3789 - mae: 25.3789\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.1031 - mae: 15.1031\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.1643 - mae: 7.1643\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 20.3318 - mae: 20.3318\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 6.3283 - mae: 6.3283\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.9961 - mae: 12.9961\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.7869 - mae: 10.7869\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4007 - mae: 11.4007\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6152 - mae: 10.6152\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.4582 - mae: 11.4582\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.3851 - mae: 11.3851\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.3986 - mae: 30.3986\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5052 - mae: 10.5052\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 28.8810 - mae: 28.8810\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.5916 - mae: 8.5916\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7378 - mae: 12.7378\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 33.6754 - mae: 33.6754\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0963 - mae: 15.0963\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.4813 - mae: 17.4813\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 22.3049 - mae: 22.3049\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.5841 - mae: 23.5841\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0008 - mae: 11.0008\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.9175 - mae: 14.9175\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9979 - mae: 17.9979\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.4482 - mae: 5.4482\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0527 - mae: 10.0527\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.0052 - mae: 14.0052\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.7782 - mae: 16.7782\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.2937 - mae: 14.2937\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.6193 - mae: 30.6193\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 7.6541 - mae: 7.6541\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 28.1428 - mae: 28.1428\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0017 - mae: 8.0017\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3933 - mae: 10.3933\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.0242 - mae: 15.0242\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 16.5653 - mae: 16.5653\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.8566 - mae: 26.8566\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.4852 - mae: 12.4852\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.4784 - mae: 12.4784\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 13.3186 - mae: 13.3186\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 29.5524 - mae: 29.5524\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.4664 - mae: 3.4664\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.2136 - mae: 15.2136\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.8327 - mae: 20.8327\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.5108 - mae: 30.5108\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.0597 - mae: 11.0597\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.8372 - mae: 12.8372\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 3.2398 - mae: 3.2398\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.6964 - mae: 16.6964\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.3883 - mae: 13.3883\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.2771 - mae: 15.2771\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.7448 - mae: 11.7448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 16.4113 - mae: 16.4113\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.8785 - mae: 13.8785\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 30.6702 - mae: 30.6702\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5880 - mae: 8.5880\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7384 - mae: 10.7384\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 17.9051 - mae: 17.9051\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 15.8095 - mae: 15.8095\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 21.3054 - mae: 21.3054\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 25.3845 - mae: 25.3845\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.9815 - mae: 23.9815\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 5.7734 - mae: 5.7734\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.0010 - mae: 20.0010\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 14.0419 - mae: 14.0419\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.6088 - mae: 30.6088\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 11.9409 - mae: 11.9409\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.6139 - mae: 23.6139\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 20.5365 - mae: 20.5365\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 4.9942 - mae: 4.9942\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.7986 - mae: 12.7986\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 13.3772 - mae: 13.3772\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 12.6727 - mae: 12.6727\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.6192 - mae: 17.6192\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 23.5629 - mae: 23.5629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.3755 - mae: 9.3755\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6316 - mae: 14.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc24b459550>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae,\n",
    "                optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "Fem6mBsnDUdS",
    "outputId": "fd9c4ee1-7885-4f0e-dd17-32e9f7a5fe7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc24c1feae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make and plot some predictions\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TbSmrikFDpE8",
    "outputId": "77307a2c-72f4-4b30-a7af-c472330e7117"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate model_3 evalaution metrics\n",
    "mae_3 = mae(y_test, y_preds_3)\n",
    "mse_3 = mse(y_test, y_preds_3)\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMwtZ03YGSdv"
   },
   "source": [
    "🔑 **Note:** You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_5UdQMOEA5y"
   },
   "source": [
    "### Comparing the results of our experiments\n",
    "\n",
    "We've run a few experiments, let's compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "OZe_HWXzESJ8",
    "outputId": "0a479747-21fa-40af-850b-639f757ede2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>18.745327</td>\n",
       "      <td>353.573364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>3.196941</td>\n",
       "      <td>13.070143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>68.713615</td>\n",
       "      <td>4808.027344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1  18.745327   353.573364\n",
       "1  model_2   3.196941    13.070143\n",
       "2  model_3  68.713615  4808.027344"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare our model's results using a pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OTx1UNfHVKZ"
   },
   "source": [
    "Looks like `model_2` performed the best..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhFEXF1iG665",
    "outputId": "6fd36e31-3373-4897-9471-158c27c34bd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oaa6e-HMHILL"
   },
   "source": [
    "> 🔑 **Note:** One of your main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work. Remember the machine learning practioner's motto: \"experiment, experiment, experiment\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DI9I7j3H1-r"
   },
   "source": [
    "## Tracking your experiments\n",
    "\n",
    "One really good habit in machine learning modelling is to track the results of your experiments.\n",
    "\n",
    "And when doing so, it can be tedious if you're running lots of experiments.\n",
    "\n",
    "Luckily, there are tools to help us!\n",
    "\n",
    "📖 **Resource:** As you build more models, you'll want to look into using:\n",
    "\n",
    "* [TensorBoard](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments (we'll see this one later).\n",
    "* [Weights & Biases](https://www.wandb.com/) - a tool for tracking all of kinds of machine learning experiments (plugs straight into TensorBoard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3fF957RIrwz"
   },
   "source": [
    "## Saving our models\n",
    "\n",
    "Saving our models allows us to use them outside of Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
    "\n",
    "There are two main formats we can save our model's too:\n",
    "\n",
    "1. The SavedModel format\n",
    "2. The HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFPevKYiIxRl",
    "outputId": "5b7f0118-faef-4c96-debe-683baa7dcab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model using the SavedModel format\n",
    "model_2.save(\"best_model_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Xg2mFS9s4eA"
   },
   "outputs": [],
   "source": [
    "# Save model using the HDF5 format\n",
    "model_2.save(\"best_model_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMTu6_fStqIQ"
   },
   "source": [
    "## Loading in a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-mCdNXLuUbV",
    "outputId": "7717519c-8a74-4376-9cf2-19468fde347a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load in the SavedModel format model\n",
    "loaded_SavedModel_format = tf.keras.models.load_model(\"best_model_SavedModel_format\")\n",
    "loaded_SavedModel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13H-0FV5utDN",
    "outputId": "9beca819-0510-442b-8d5a-a4c933275d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:8 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc24b0d41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model_2 predictions with SavedModel format model predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
    "model_2_preds == loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyATYIrLuxrM",
    "outputId": "0ec02eee-792d-40eb-fcc7-5e69bc69e385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the MAE of model_2 preds and loaded_SavedModel_preds\n",
    "mae(y_true=y_test, y_pred=model_2_preds) == mae(y_true=y_test, y_pred=loaded_SavedModel_format_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYRN_QQ1v36P",
    "outputId": "c0811700-93aa-43c4-c9e0-325733ba8eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load in a model using the .h5 format\n",
    "loaded_h5_model = tf.keras.models.load_model(\"/content/best_model_HDF5_format.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tAE0IE7wHWz",
    "outputId": "c9559f8a-971c-40f8-9d0e-eedc44dfbca5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc24b09e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see if loaded .h5 model predictions match model_2\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUFnorbpwon_"
   },
   "source": [
    "## Download a model (or any other file) from Google Colab\n",
    "\n",
    "If you want to download your files from Google Colab:\n",
    "\n",
    "1. You can go to the \"files\" tab and right click on the file you're after and click \"download\".\n",
    "2. Use code (see the cell below).\n",
    "3. Save it to Google Drive by connecting Google Drive and copying it there (see 2nd code cell below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "MrfvCrjgxSg2",
    "outputId": "ca8ecbec-2b97-41c2-a1dc-ccc021b4eac4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_43368988-9e9b-402d-9c02-2cfdb5d7c113\", \"best_model_HDF5_format.h5\", 16952)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download a file from Google Colab\n",
    "from google.colab import files\n",
    "files.download(\"/content/best_model_HDF5_format.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eQEQSJ8xypc"
   },
   "outputs": [],
   "source": [
    "# Save a file from Google Colab to Google Drive (requires mounting Google Drive)\n",
    "!cp /content/best_model_HDF5_format.h5 /content/drive/MyDrive/tensorflow_course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ODwgyDRyaBh",
    "outputId": "c3d45bf7-156c-4496-c201-2e75fed8073a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101_food_class_10_percent_saved_big_dog_model  food_vision\n",
      "10_food_classes_model_5_epochs\t\t       skim_lit\n",
      "best_model_HDF5_format.h5\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/MyDrive/tensorflow_course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-Yv-2Bhymy6"
   },
   "source": [
    "## A larger example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 14:17:59.920591: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-22 14:17:59.932147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732295879.941652   39493 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732295879.944520   39493 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 14:17:59.954244: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6vZ8AIbD1XpM"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "uPQmsO6Y2Exv",
    "outputId": "1de0681c-a05c-4f1e-c0f1-5d387ef1b497"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the insurance dataset\n",
    "insurance = pd.read_csv(\"archive/insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "robZtd8l2y19",
    "outputId": "7f66e903-33c8-42c8-d4e1-b24eb103d1d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try one-hot encode our DataFrame so it's all numbers\n",
    "from numpy import int64\n",
    "\n",
    "\n",
    "insurance_one_hot = pd.get_dummies(insurance, dtype=int64)\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jGU53qHw3yTQ"
   },
   "outputs": [],
   "source": [
    "# Create X & y values (features and labels)\n",
    "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
    "y = insurance_one_hot[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "879Oxm4Z5I9H",
    "outputId": "17ac3ffd-8b7d-414f-d796-988dedaddda1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View X\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkDW7YGa5MNu",
    "outputId": "aade9646-73d6-446b-ea24-ed9fe62cb53d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/lucasvillefort/Desktop/COURSE/tensorflow-deep-learning/.venv/lib/python3.12/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a1cIygD46Ng",
    "outputId": "f0976ada-c8d9-4d21-bac9-41523709c96c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "len(X), len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6A8y4WT47s4",
    "outputId": "89575733-73dd-40d3-dc2c-6188015085e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732296310.475012   39493 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6270 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732296310.807181   40515 service.cc:148] XLA service 0x70c994006460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732296310.807214   40515 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-11-22 14:25:10.816660: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732296310.835278   40515 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/34\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13134.1250 - mae: 12941.5684   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732296311.122707   40515 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 10078.7627 - mae: 10078.7627\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 7560.0664 - mae: 7560.0664\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 8014.2021 - mae: 8014.2021\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - loss: 7142.1313 - mae: 7142.1313\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 7237.0933 - mae: 7237.0933\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 7276.5229 - mae: 7276.5229\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 7587.3320 - mae: 7587.3320\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 7828.6250 - mae: 7828.6250\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 7573.9482 - mae: 7573.9482\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 7396.6167 - mae: 7396.6167\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 7465.4502 - mae: 7465.4502\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 7596.9907 - mae: 7596.9907\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - loss: 7506.0254 - mae: 7506.0254\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 7492.9165 - mae: 7492.9165\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 7506.7490 - mae: 7506.7490\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 7516.2007 - mae: 7516.2007\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 7408.1641 - mae: 7408.1641\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7580.4614 - mae: 7580.4614 \n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 7382.5381 - mae: 7382.5381\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 7426.4062 - mae: 7426.4062\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 7441.2778 - mae: 7441.2778\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 7070.8882 - mae: 7070.8882\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 7426.4883 - mae: 7426.4883\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 7486.5630 - mae: 7486.5630\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 7343.9155 - mae: 7343.9155\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 7571.0537 - mae: 7571.0537\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - loss: 7514.0566 - mae: 7514.0566\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - loss: 7468.8472 - mae: 7468.8472\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 7385.6216 - mae: 7385.6216\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 7583.7598 - mae: 7583.7598\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 7139.3413 - mae: 7139.3413\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 7472.8970 - mae: 7472.8970\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 7404.0371 - mae: 7404.0371\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 7569.5986 - mae: 7569.5986\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 7518.9492 - mae: 7518.9492\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 7383.0308 - mae: 7383.0308\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 7072.4697 - mae: 7072.4697\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 7425.0298 - mae: 7425.0298\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 7490.3774 - mae: 7490.3774\n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 7343.6733 - mae: 7343.6733\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 7496.7964 - mae: 7496.7964\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 7289.4126 - mae: 7289.4126\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 7471.6157 - mae: 7471.6157\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 7452.0815 - mae: 7452.0815\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 7376.9731 - mae: 7376.9731\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 7450.9902 - mae: 7450.9902\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 7440.8271 - mae: 7440.8271\n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 7319.1260 - mae: 7319.1260\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 7055.5781 - mae: 7055.5781\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 7287.7393 - mae: 7287.7393\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 7421.2559 - mae: 7421.2559\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 7389.1069 - mae: 7389.1069\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 7038.2949 - mae: 7038.2949\n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 7065.7476 - mae: 7065.7476\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 7103.1230 - mae: 7103.1230\n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 7427.8389 - mae: 7427.8389\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 7488.4727 - mae: 7488.4727\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 7313.4834 - mae: 7313.4834\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6986.9912 - mae: 6986.9912\n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 6984.3350 - mae: 6984.3350\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 547us/step - loss: 7536.3579 - mae: 7536.3579\n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 7674.0391 - mae: 7674.0391\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 7240.9526 - mae: 7240.9526\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 7355.9287 - mae: 7355.9287\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 7608.8618 - mae: 7608.8618\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 7375.5869 - mae: 7375.5869\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 7221.0229 - mae: 7221.0229\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 7322.4546 - mae: 7322.4546\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 7283.7690 - mae: 7283.7690\n",
      "Epoch 70/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 7417.2720 - mae: 7417.2720\n",
      "Epoch 71/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7208.2349 - mae: 7208.2349\n",
      "Epoch 72/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 7705.3325 - mae: 7705.3325\n",
      "Epoch 73/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 6868.3862 - mae: 6868.3862\n",
      "Epoch 74/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 7352.8486 - mae: 7352.8486\n",
      "Epoch 75/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - loss: 7336.1377 - mae: 7336.1377\n",
      "Epoch 76/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 7311.6060 - mae: 7311.6060\n",
      "Epoch 77/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 7310.5195 - mae: 7310.5195\n",
      "Epoch 78/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 7436.1162 - mae: 7436.1162\n",
      "Epoch 79/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - loss: 7405.2983 - mae: 7405.2983\n",
      "Epoch 80/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 7017.3125 - mae: 7017.3125\n",
      "Epoch 81/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 7238.1289 - mae: 7238.1289\n",
      "Epoch 82/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 7123.0127 - mae: 7123.0127\n",
      "Epoch 83/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 7270.7661 - mae: 7270.7661\n",
      "Epoch 84/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 7280.9995 - mae: 7280.9995\n",
      "Epoch 85/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 7229.6914 - mae: 7229.6914\n",
      "Epoch 86/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 7270.0928 - mae: 7270.0928\n",
      "Epoch 87/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 6891.9692 - mae: 6891.9692\n",
      "Epoch 88/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 7598.0366 - mae: 7598.0366\n",
      "Epoch 89/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 7146.5981 - mae: 7146.5981\n",
      "Epoch 90/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 7365.0962 - mae: 7365.0962\n",
      "Epoch 91/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 7411.9829 - mae: 7411.9829\n",
      "Epoch 92/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 7147.8350 - mae: 7147.8350\n",
      "Epoch 93/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 7097.1934 - mae: 7097.1934\n",
      "Epoch 94/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 6893.8760 - mae: 6893.8760\n",
      "Epoch 95/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 7186.9873 - mae: 7186.9873\n",
      "Epoch 96/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 6749.0981 - mae: 6749.0981\n",
      "Epoch 97/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 7304.6987 - mae: 7304.6987\n",
      "Epoch 98/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 7398.0303 - mae: 7398.0303\n",
      "Epoch 99/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 7206.4404 - mae: 7206.4404\n",
      "Epoch 100/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 6709.8599 - mae: 6709.8599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70cbe0ff5790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a neural network (sort of like model_2 above)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model\n",
    "insurance_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model.compile(loss=tf.keras.losses.mae,\n",
    "                        optimizer=tf.keras.optimizers.SGD(),\n",
    "                        metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmRjvYMu6Yeu",
    "outputId": "111b0376-a856-4153-aa9e-fd8a7c25b87e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7986.5288 - mae: 7986.5288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7978.7314453125, 7978.7314453125]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the insurance model on the test data\n",
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0u1tPVZu7bx9",
    "outputId": "64946515-86d8-4d8a-b9ec-eba0f398fd44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(9575.4421), np.float64(13346.089736364485))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median(), y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEMaHr1m7j9n"
   },
   "source": [
    "Right now it looks like our model isn't performing too well... let's try and improve it!\n",
    "\n",
    "To (try) improve our model, we'll run 2 experiments:\n",
    "1. Add an extra layer with more hidden units and use the Adam optimizer\n",
    "2. Same as above but train for longer (200 epochs)\n",
    "3. (insert your own experiment here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PV6yAHm9dR0",
    "outputId": "d67e2b54-2607-4031-8618-5d4eb1ac8fc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       " 560    46  19.950         2           1         0          1           0   \n",
       " 1285   47  24.320         0           1         0          1           0   \n",
       " 1142   52  24.860         0           1         0          1           0   \n",
       " 969    39  34.320         5           1         0          1           0   \n",
       " 486    54  21.470         3           1         0          1           0   \n",
       " ...   ...     ...       ...         ...       ...        ...         ...   \n",
       " 1095   18  31.350         4           1         0          1           0   \n",
       " 1130   39  23.870         5           1         0          1           0   \n",
       " 1294   58  25.175         0           0         1          1           0   \n",
       " 860    37  47.600         2           1         0          0           1   \n",
       " 1126   55  29.900         0           0         1          1           0   \n",
       " \n",
       "       region_northeast  region_northwest  region_southeast  region_southwest  \n",
       " 560                  0                 1                 0                 0  \n",
       " 1285                 1                 0                 0                 0  \n",
       " 1142                 0                 0                 1                 0  \n",
       " 969                  0                 0                 1                 0  \n",
       " 486                  0                 1                 0                 0  \n",
       " ...                ...               ...               ...               ...  \n",
       " 1095                 1                 0                 0                 0  \n",
       " 1130                 0                 0                 1                 0  \n",
       " 1294                 1                 0                 0                 0  \n",
       " 860                  0                 0                 0                 1  \n",
       " 1126                 0                 0                 0                 1  \n",
       " \n",
       " [1070 rows x 11 columns],\n",
       " 560      9193.83850\n",
       " 1285     8534.67180\n",
       " 1142    27117.99378\n",
       " 969      8596.82780\n",
       " 486     12475.35130\n",
       "            ...     \n",
       " 1095     4561.18850\n",
       " 1130     8582.30230\n",
       " 1294    11931.12525\n",
       " 860     46113.51100\n",
       " 1126    10214.63600\n",
       " Name: charges, Length: 1070, dtype: float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2437V9zH758n",
    "outputId": "198be635-15ba-425d-b035-cf7d9b781640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 13276.6328 - mae: 13276.6328\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 13141.1260 - mae: 13141.1260\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 12865.3994 - mae: 12865.3994\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 12300.2559 - mae: 12300.2559\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 11272.5879 - mae: 11272.5879\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 9894.6201 - mae: 9894.6201\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 8416.1064 - mae: 8416.1064\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 7560.4434 - mae: 7560.4434\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 7429.9878 - mae: 7429.9878\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 7376.7422 - mae: 7376.7422\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 7354.9092 - mae: 7354.9092\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 7339.2417 - mae: 7339.2417\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 7309.6821 - mae: 7309.6821\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - loss: 7286.8408 - mae: 7286.8408\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - loss: 7263.2905 - mae: 7263.2905\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 7239.8730 - mae: 7239.8730\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 7238.2158 - mae: 7238.2158\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 7190.5688 - mae: 7190.5688\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 7165.3960 - mae: 7165.3960\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 7138.9395 - mae: 7138.9395\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 7111.5801 - mae: 7111.5801\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 7083.4570 - mae: 7083.4570\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 7054.0684 - mae: 7054.0684\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - loss: 7045.5181 - mae: 7045.5181\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6997.1660 - mae: 6997.1660\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 6960.4023 - mae: 6960.4023\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 6965.5137 - mae: 6965.5137\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6896.3887 - mae: 6896.3887\n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 6856.3105 - mae: 6856.3105\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 6819.0210 - mae: 6819.0210\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 6791.7124 - mae: 6791.7124\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 6743.6104 - mae: 6743.6104\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 6722.1797 - mae: 6722.1797\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 6685.3066 - mae: 6685.3066\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 6636.3477 - mae: 6636.3477\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 6580.7852 - mae: 6580.7852\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 6586.0415 - mae: 6586.0415\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 6498.6167 - mae: 6498.6167\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 6459.5137 - mae: 6459.5137\n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 6425.8589 - mae: 6425.8589\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 6398.4995 - mae: 6398.4995\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 6422.5029 - mae: 6422.5029\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 6373.5171 - mae: 6373.5171\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 6334.8623 - mae: 6334.8623\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 6324.2695 - mae: 6324.2695\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 6309.9268 - mae: 6309.9268\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 6308.2241 - mae: 6308.2241\n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 6302.7524 - mae: 6302.7524\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 6274.0703 - mae: 6274.0703\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - loss: 6255.2812 - mae: 6255.2812\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6241.5986 - mae: 6241.5986\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 6227.9775 - mae: 6227.9775\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 6213.7920 - mae: 6213.7920\n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 6199.6216 - mae: 6199.6216\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - loss: 6179.9927 - mae: 6179.9927\n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 6170.1582 - mae: 6170.1582\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 6155.0713 - mae: 6155.0713\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 6139.7080 - mae: 6139.7080\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 6109.3389 - mae: 6109.3389\n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 6107.8267 - mae: 6107.8267\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 6103.7598 - mae: 6103.7598\n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 6074.1133 - mae: 6074.1133\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 6056.4224 - mae: 6056.4224\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - loss: 6044.0479 - mae: 6044.0479\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 6020.2266 - mae: 6020.2266\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 6001.9048 - mae: 6001.9048\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 5982.4448 - mae: 5982.4448\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 5962.7847 - mae: 5962.7847\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 5952.9976 - mae: 5952.9976\n",
      "Epoch 70/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 5921.3789 - mae: 5921.3789\n",
      "Epoch 71/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 5916.2236 - mae: 5916.2236\n",
      "Epoch 72/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 5877.6211 - mae: 5877.6211\n",
      "Epoch 73/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 5854.5684 - mae: 5854.5684\n",
      "Epoch 74/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 5830.7627 - mae: 5830.7627\n",
      "Epoch 75/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 5805.9917 - mae: 5805.9917\n",
      "Epoch 76/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 5782.5420 - mae: 5782.5420\n",
      "Epoch 77/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 5753.1763 - mae: 5753.1763\n",
      "Epoch 78/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - loss: 5725.2671 - mae: 5725.2671\n",
      "Epoch 79/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 5696.9736 - mae: 5696.9736\n",
      "Epoch 80/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 5683.2100 - mae: 5683.2100\n",
      "Epoch 81/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - loss: 5636.1787 - mae: 5636.1787\n",
      "Epoch 82/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - loss: 5603.3550 - mae: 5603.3550\n",
      "Epoch 83/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 5569.4673 - mae: 5569.4673\n",
      "Epoch 84/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 5553.8037 - mae: 5553.8037\n",
      "Epoch 85/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 5494.5557 - mae: 5494.5557\n",
      "Epoch 86/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - loss: 5460.0947 - mae: 5460.0947\n",
      "Epoch 87/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - loss: 5421.1650 - mae: 5421.1650\n",
      "Epoch 88/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 5379.4058 - mae: 5379.4058\n",
      "Epoch 89/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 5349.9634 - mae: 5349.9634\n",
      "Epoch 90/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 5305.1152 - mae: 5305.1152\n",
      "Epoch 91/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 5243.3188 - mae: 5243.3188\n",
      "Epoch 92/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 5193.7495 - mae: 5193.7495\n",
      "Epoch 93/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 5142.1177 - mae: 5142.1177\n",
      "Epoch 94/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 5086.7290 - mae: 5086.7290\n",
      "Epoch 95/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 5029.7471 - mae: 5029.7471\n",
      "Epoch 96/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - loss: 4969.0063 - mae: 4969.0063\n",
      "Epoch 97/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 4923.9658 - mae: 4923.9658\n",
      "Epoch 98/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 4837.4683 - mae: 4837.4683\n",
      "Epoch 99/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 4768.4058 - mae: 4768.4058\n",
      "Epoch 100/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 4690.9526 - mae: 4690.9526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70cbd504c890>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRqPnfiW9KDy",
    "outputId": "a84f43c5-b4c7-4ba3-c532-84837cc50fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4813.2788 - mae: 4813.2788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4679.712890625, 4679.712890625]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the larger model\n",
    "insurance_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnV2Vsn79Wj1",
    "outputId": "14623c60-bd4f-4152-b375-22f29cebbcf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 633us/step - loss: 8014.0015 - mae: 8014.0015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7978.7314453125, 7978.7314453125]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKl1-Eir98Si",
    "outputId": "d4c0ec41-61af-4a6a-922b-2ced18224249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 13240.3037 - mae: 13240.3037 \n",
      "Epoch 2/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 13126.1963 - mae: 13126.1963\n",
      "Epoch 3/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 12825.7832 - mae: 12825.7832\n",
      "Epoch 4/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 12221.9375 - mae: 12221.9375\n",
      "Epoch 5/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 11154.5273 - mae: 11154.5273\n",
      "Epoch 6/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 9794.0049 - mae: 9794.0049\n",
      "Epoch 7/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 8371.0049 - mae: 8371.0049\n",
      "Epoch 8/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 7548.9385 - mae: 7548.9385\n",
      "Epoch 9/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 7399.7222 - mae: 7399.7222\n",
      "Epoch 10/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 7382.1079 - mae: 7382.1079\n",
      "Epoch 11/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7349.1538 - mae: 7349.1538\n",
      "Epoch 12/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 7327.6421 - mae: 7327.6421\n",
      "Epoch 13/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - loss: 7305.8325 - mae: 7305.8325\n",
      "Epoch 14/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 7283.3462 - mae: 7283.3462\n",
      "Epoch 15/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 7260.8452 - mae: 7260.8452\n",
      "Epoch 16/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 7238.1777 - mae: 7238.1777\n",
      "Epoch 17/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - loss: 7214.8193 - mae: 7214.8193\n",
      "Epoch 18/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - loss: 7191.0347 - mae: 7191.0347\n",
      "Epoch 19/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 7167.2080 - mae: 7167.2080\n",
      "Epoch 20/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 7142.8306 - mae: 7142.8306\n",
      "Epoch 21/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 7148.0454 - mae: 7148.0454\n",
      "Epoch 22/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 7091.8105 - mae: 7091.8105\n",
      "Epoch 23/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 7083.2549 - mae: 7083.2549\n",
      "Epoch 24/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 7036.7607 - mae: 7036.7607\n",
      "Epoch 25/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 7008.6426 - mae: 7008.6426\n",
      "Epoch 26/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 6980.2646 - mae: 6980.2646\n",
      "Epoch 27/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - loss: 6951.2500 - mae: 6951.2500\n",
      "Epoch 28/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 577us/step - loss: 6920.4165 - mae: 6920.4165\n",
      "Epoch 29/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 6889.0962 - mae: 6889.0962\n",
      "Epoch 30/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 6856.4746 - mae: 6856.4746\n",
      "Epoch 31/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 6843.5415 - mae: 6843.5415\n",
      "Epoch 32/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - loss: 6788.4014 - mae: 6788.4014\n",
      "Epoch 33/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 6775.3364 - mae: 6775.3364\n",
      "Epoch 34/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 6736.6216 - mae: 6736.6216\n",
      "Epoch 35/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - loss: 6682.5918 - mae: 6682.5918\n",
      "Epoch 36/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 6662.0244 - mae: 6662.0244\n",
      "Epoch 37/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 6605.4282 - mae: 6605.4282\n",
      "Epoch 38/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 6567.2197 - mae: 6567.2197\n",
      "Epoch 39/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 6528.7627 - mae: 6528.7627\n",
      "Epoch 40/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 6491.1460 - mae: 6491.1460\n",
      "Epoch 41/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 6474.9419 - mae: 6474.9419\n",
      "Epoch 42/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 6421.8315 - mae: 6421.8315\n",
      "Epoch 43/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - loss: 6395.3267 - mae: 6395.3267\n",
      "Epoch 44/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 6373.8320 - mae: 6373.8320\n",
      "Epoch 45/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 6354.9824 - mae: 6354.9824\n",
      "Epoch 46/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 6338.9663 - mae: 6338.9663\n",
      "Epoch 47/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 6323.5874 - mae: 6323.5874\n",
      "Epoch 48/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 6309.4292 - mae: 6309.4292\n",
      "Epoch 49/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 6313.9409 - mae: 6313.9409\n",
      "Epoch 50/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - loss: 6282.3145 - mae: 6282.3145\n",
      "Epoch 51/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 6274.4692 - mae: 6274.4692\n",
      "Epoch 52/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 6272.6729 - mae: 6272.6729\n",
      "Epoch 53/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 6243.0073 - mae: 6243.0073\n",
      "Epoch 54/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - loss: 6231.1758 - mae: 6231.1758\n",
      "Epoch 55/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 6216.1729 - mae: 6216.1729\n",
      "Epoch 56/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 6202.5225 - mae: 6202.5225\n",
      "Epoch 57/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 6193.9307 - mae: 6193.9307\n",
      "Epoch 58/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 6173.9800 - mae: 6173.9800\n",
      "Epoch 59/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 6159.2261 - mae: 6159.2261\n",
      "Epoch 60/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 6173.7041 - mae: 6173.7041\n",
      "Epoch 61/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - loss: 6128.9336 - mae: 6128.9336\n",
      "Epoch 62/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - loss: 6113.3672 - mae: 6113.3672\n",
      "Epoch 63/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 6112.1099 - mae: 6112.1099\n",
      "Epoch 64/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 6080.9868 - mae: 6080.9868\n",
      "Epoch 65/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 6063.8750 - mae: 6063.8750\n",
      "Epoch 66/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 6051.9951 - mae: 6051.9951\n",
      "Epoch 67/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 6045.5620 - mae: 6045.5620\n",
      "Epoch 68/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 6031.0391 - mae: 6031.0391\n",
      "Epoch 69/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 5991.9692 - mae: 5991.9692\n",
      "Epoch 70/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 5992.9756 - mae: 5992.9756\n",
      "Epoch 71/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 5941.1650 - mae: 5941.1650\n",
      "Epoch 72/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 5932.2871 - mae: 5932.2871\n",
      "Epoch 73/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 5937.4468 - mae: 5937.4468\n",
      "Epoch 74/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 5889.5264 - mae: 5889.5264\n",
      "Epoch 75/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 5887.1060 - mae: 5887.1060\n",
      "Epoch 76/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 5859.8486 - mae: 5859.8486\n",
      "Epoch 77/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 5828.2944 - mae: 5828.2944\n",
      "Epoch 78/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - loss: 5793.9180 - mae: 5793.9180\n",
      "Epoch 79/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 5767.6011 - mae: 5767.6011\n",
      "Epoch 80/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - loss: 5740.1636 - mae: 5740.1636\n",
      "Epoch 81/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 5737.2656 - mae: 5737.2656\n",
      "Epoch 82/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 5683.0747 - mae: 5683.0747\n",
      "Epoch 83/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 5663.6123 - mae: 5663.6123\n",
      "Epoch 84/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 5620.1895 - mae: 5620.1895\n",
      "Epoch 85/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 5586.4839 - mae: 5586.4839\n",
      "Epoch 86/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 5560.4907 - mae: 5560.4907\n",
      "Epoch 87/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 5518.1890 - mae: 5518.1890\n",
      "Epoch 88/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 5478.4292 - mae: 5478.4292\n",
      "Epoch 89/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 5454.5659 - mae: 5454.5659\n",
      "Epoch 90/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 5417.5698 - mae: 5417.5698\n",
      "Epoch 91/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 5378.0190 - mae: 5378.0190\n",
      "Epoch 92/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 5324.2466 - mae: 5324.2466\n",
      "Epoch 93/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 5283.6528 - mae: 5283.6528\n",
      "Epoch 94/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - loss: 5230.8398 - mae: 5230.8398\n",
      "Epoch 95/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 5158.0430 - mae: 5158.0430\n",
      "Epoch 96/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 5102.7749 - mae: 5102.7749\n",
      "Epoch 97/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 5046.0879 - mae: 5046.0879\n",
      "Epoch 98/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 4986.2651 - mae: 4986.2651\n",
      "Epoch 99/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 4920.5264 - mae: 4920.5264\n",
      "Epoch 100/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 4868.9971 - mae: 4868.9971\n",
      "Epoch 101/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 4799.2095 - mae: 4799.2095\n",
      "Epoch 102/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 4715.6050 - mae: 4715.6050\n",
      "Epoch 103/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 4650.4692 - mae: 4650.4692\n",
      "Epoch 104/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579us/step - loss: 4550.7124 - mae: 4550.7124\n",
      "Epoch 105/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 4466.6377 - mae: 4466.6377\n",
      "Epoch 106/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 4375.2896 - mae: 4375.2896\n",
      "Epoch 107/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 4285.1709 - mae: 4285.1709\n",
      "Epoch 108/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 4205.6597 - mae: 4205.6597\n",
      "Epoch 109/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - loss: 4111.4658 - mae: 4111.4658\n",
      "Epoch 110/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 4031.7312 - mae: 4031.7312\n",
      "Epoch 111/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 3953.6597 - mae: 3953.6597\n",
      "Epoch 112/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 3911.7783 - mae: 3911.7783\n",
      "Epoch 113/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - loss: 3857.9185 - mae: 3857.9185\n",
      "Epoch 114/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 3821.9980 - mae: 3821.9980\n",
      "Epoch 115/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 3791.5359 - mae: 3791.5359\n",
      "Epoch 116/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3778.4463 - mae: 3778.4463  \n",
      "Epoch 117/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 3766.4473 - mae: 3766.4473\n",
      "Epoch 118/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 3753.4478 - mae: 3753.4478\n",
      "Epoch 119/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 3746.4207 - mae: 3746.4207\n",
      "Epoch 120/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 3737.8557 - mae: 3737.8557\n",
      "Epoch 121/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 3734.3140 - mae: 3734.3140\n",
      "Epoch 122/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 3726.9265 - mae: 3726.9265\n",
      "Epoch 123/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 3725.3223 - mae: 3725.3223\n",
      "Epoch 124/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 3718.4302 - mae: 3718.4302\n",
      "Epoch 125/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 3725.9375 - mae: 3725.9375\n",
      "Epoch 126/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 3727.0640 - mae: 3727.0640\n",
      "Epoch 127/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 3706.7820 - mae: 3706.7820\n",
      "Epoch 128/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - loss: 3708.2053 - mae: 3708.2053\n",
      "Epoch 129/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 3704.7800 - mae: 3704.7800\n",
      "Epoch 130/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 3702.0024 - mae: 3702.0024\n",
      "Epoch 131/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 3699.4204 - mae: 3699.4204\n",
      "Epoch 132/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 3706.2947 - mae: 3706.2947\n",
      "Epoch 133/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 3696.1433 - mae: 3696.1433\n",
      "Epoch 134/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 3674.9543 - mae: 3674.9543\n",
      "Epoch 135/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 3692.2756 - mae: 3692.2756\n",
      "Epoch 136/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 3690.5491 - mae: 3690.5491\n",
      "Epoch 137/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 3685.6045 - mae: 3685.6045\n",
      "Epoch 138/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - loss: 3694.9822 - mae: 3694.9822\n",
      "Epoch 139/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 3685.5566 - mae: 3685.5566\n",
      "Epoch 140/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - loss: 3683.3018 - mae: 3683.3018\n",
      "Epoch 141/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 3690.3997 - mae: 3690.3997\n",
      "Epoch 142/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 3681.4966 - mae: 3681.4966\n",
      "Epoch 143/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 3681.0171 - mae: 3681.0171\n",
      "Epoch 144/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 3678.4233 - mae: 3678.4233\n",
      "Epoch 145/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 3676.4272 - mae: 3676.4272\n",
      "Epoch 146/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 3676.4102 - mae: 3676.4102\n",
      "Epoch 147/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 3673.9875 - mae: 3673.9875\n",
      "Epoch 148/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 3680.2720 - mae: 3680.2720\n",
      "Epoch 149/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 3685.2986 - mae: 3685.2986\n",
      "Epoch 150/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 3684.0229 - mae: 3684.0229\n",
      "Epoch 151/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 3677.3220 - mae: 3677.3220\n",
      "Epoch 152/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 3666.3396 - mae: 3666.3396\n",
      "Epoch 153/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 3665.5581 - mae: 3665.5581\n",
      "Epoch 154/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 3665.3242 - mae: 3665.3242\n",
      "Epoch 155/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 3663.0525 - mae: 3663.0525\n",
      "Epoch 156/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 3679.3643 - mae: 3679.3643\n",
      "Epoch 157/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 3661.4788 - mae: 3661.4788\n",
      "Epoch 158/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 3658.6257 - mae: 3658.6257\n",
      "Epoch 159/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 3664.5916 - mae: 3664.5916\n",
      "Epoch 160/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3671.6772 - mae: 3671.6772\n",
      "Epoch 161/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 3654.7634 - mae: 3654.7634\n",
      "Epoch 162/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 3677.3757 - mae: 3677.3757\n",
      "Epoch 163/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - loss: 3660.0186 - mae: 3660.0186\n",
      "Epoch 164/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3653.0408 - mae: 3653.0408\n",
      "Epoch 165/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3649.0569 - mae: 3649.0569\n",
      "Epoch 166/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 3644.4724 - mae: 3644.4724\n",
      "Epoch 167/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 3654.2825 - mae: 3654.2825\n",
      "Epoch 168/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 3646.0603 - mae: 3646.0603\n",
      "Epoch 169/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - loss: 3642.7932 - mae: 3642.7932\n",
      "Epoch 170/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - loss: 3643.9114 - mae: 3643.9114\n",
      "Epoch 171/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - loss: 3639.4368 - mae: 3639.4368\n",
      "Epoch 172/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3643.6106 - mae: 3643.6106  \n",
      "Epoch 173/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 3643.1084 - mae: 3643.1084\n",
      "Epoch 174/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 3641.1309 - mae: 3641.1309\n",
      "Epoch 175/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 3638.8877 - mae: 3638.8877\n",
      "Epoch 176/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - loss: 3652.7437 - mae: 3652.7437\n",
      "Epoch 177/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 3638.7000 - mae: 3638.7000\n",
      "Epoch 178/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534us/step - loss: 3634.7732 - mae: 3634.7732\n",
      "Epoch 179/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 3637.4863 - mae: 3637.4863\n",
      "Epoch 180/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 3635.1833 - mae: 3635.1833\n",
      "Epoch 181/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 3637.3550 - mae: 3637.3550\n",
      "Epoch 182/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 3632.3928 - mae: 3632.3928\n",
      "Epoch 183/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 3632.6479 - mae: 3632.6479\n",
      "Epoch 184/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 3632.6482 - mae: 3632.6482\n",
      "Epoch 185/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 3636.2473 - mae: 3636.2473\n",
      "Epoch 186/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 3628.8315 - mae: 3628.8315\n",
      "Epoch 187/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - loss: 3634.8271 - mae: 3634.8271\n",
      "Epoch 188/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 3618.2334 - mae: 3618.2334\n",
      "Epoch 189/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 3628.4375 - mae: 3628.4375\n",
      "Epoch 190/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - loss: 3618.8003 - mae: 3618.8003\n",
      "Epoch 191/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 3622.9312 - mae: 3622.9312\n",
      "Epoch 192/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 3621.7061 - mae: 3621.7061\n",
      "Epoch 193/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 3639.8718 - mae: 3639.8718\n",
      "Epoch 194/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 3624.7070 - mae: 3624.7070\n",
      "Epoch 195/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 3612.4761 - mae: 3612.4761\n",
      "Epoch 196/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 3617.7961 - mae: 3617.7961\n",
      "Epoch 197/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 3625.0591 - mae: 3625.0591\n",
      "Epoch 198/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 3616.3723 - mae: 3616.3723\n",
      "Epoch 199/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 3613.9744 - mae: 3613.9744\n",
      "Epoch 200/200\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 3615.3152 - mae: 3615.3152\n"
     ]
    }
   ],
   "source": [
    "# Set random set\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model (same as above)\n",
    "insurance_model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)                                \n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "history = insurance_model_3.fit(X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DX918PcL-n8s",
    "outputId": "2bda52d1-02af-4a87-bdd5-097e2614302e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3467.1589 - mae: 3467.1589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3401.486083984375, 3401.486083984375]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate our third model\n",
    "insurance_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImGrhOUu-w8J",
    "outputId": "62ad1d4e-bc0f-49f8-8c87-9013befa9e4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7986.5288 - mae: 7986.5288  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7978.7314453125, 7978.7314453125]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "5obI_2qh-3Yl",
    "outputId": "072602d9-6d95-4a5d-c2d4-2e0906ec4379"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history (also known as a loss curve or a training curve)\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifIrgZbp_JBA"
   },
   "source": [
    "> 🤔 **Question:** How long should you train for?\n",
    "\n",
    "It depends. Really... it depends on the problem you're working on. However, many people have asked this question before... so TensorFlow has a solution! It's called the [EarlyStopping Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), which is a TensorFlow component you can add to your model to stop training once it stops improving a certain metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19mmj6JTACaR"
   },
   "source": [
    "## Preprocessing data (normalization and standardization)\n",
    "\n",
    "In terms of scaling values, neural networks tend to prefer normalization.\n",
    "\n",
    "If you're not sure on which to use, you could try both and see which performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "A9EZSNF_3MaY",
    "outputId": "fb545d41-a657-4d70-a546-04b0250efe62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in the insurance dataframe\n",
    "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8VN6GfP4Dsn"
   },
   "source": [
    "To prepare our data, we can borrow a few classes from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XR8i1bHZAV6o"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in these columns between 0 and 1 \n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ")\n",
    "\n",
    "# Create X & y\n",
    "X = insurance.drop(\"charges\", axis=1)\n",
    "y = insurance[\"charges\"]\n",
    "\n",
    "# Build our train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the column transformer to our training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGD73N7651a3",
    "outputId": "49eab515-e76a-490f-8b5b-da565e274309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does our data look like now?\n",
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQsT3lTJ55qS",
    "outputId": "d93030f8-731d-4ccb-f8aa-ec671dc30eef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_tiE2Dj86M6g",
    "outputId": "97987c42-72b7-4cc5-b2d2-37dc69df9c03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7o1A7kL6Yrm"
   },
   "source": [
    "Beautiful! Our data has been normalized and one hot encoded. Now let's build a neural network model on it and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDF9TU0_6W2r",
    "outputId": "7fd4fee5-425e-43b5-d192-787a119983eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 13297.5703 - mae: 13297.5703\n",
      "Epoch 2/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 13315.5215 - mae: 13315.5215\n",
      "Epoch 3/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - loss: 13276.1396 - mae: 13276.1396\n",
      "Epoch 4/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 13225.5996 - mae: 13225.5996\n",
      "Epoch 5/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 13148.4746 - mae: 13148.4746\n",
      "Epoch 6/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 13025.8145 - mae: 13025.8145\n",
      "Epoch 7/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 12855.4990 - mae: 12855.4990\n",
      "Epoch 8/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - loss: 12600.8242 - mae: 12600.8242\n",
      "Epoch 9/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 12312.3799 - mae: 12312.3799\n",
      "Epoch 10/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 11875.4170 - mae: 11875.4170\n",
      "Epoch 11/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - loss: 11400.2793 - mae: 11400.2793\n",
      "Epoch 12/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 10893.8867 - mae: 10893.8867\n",
      "Epoch 13/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 10393.0742 - mae: 10393.0742\n",
      "Epoch 14/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 9891.5127 - mae: 9891.5127\n",
      "Epoch 15/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 9411.7217 - mae: 9411.7217\n",
      "Epoch 16/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 8994.0566 - mae: 8994.0566\n",
      "Epoch 17/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 8639.5459 - mae: 8639.5459\n",
      "Epoch 18/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 8360.1621 - mae: 8360.1621\n",
      "Epoch 19/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 8155.1816 - mae: 8155.1816\n",
      "Epoch 20/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 8009.6606 - mae: 8009.6606\n",
      "Epoch 21/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 7909.2100 - mae: 7909.2100\n",
      "Epoch 22/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 7837.1240 - mae: 7837.1240\n",
      "Epoch 23/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 7803.3682 - mae: 7803.3682\n",
      "Epoch 24/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - loss: 7728.8823 - mae: 7728.8823\n",
      "Epoch 25/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 7704.7632 - mae: 7704.7632\n",
      "Epoch 26/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 7636.3389 - mae: 7636.3389\n",
      "Epoch 27/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 7599.7671 - mae: 7599.7671\n",
      "Epoch 28/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7546.9336 - mae: 7546.9336 \n",
      "Epoch 29/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 7503.0942 - mae: 7503.0942\n",
      "Epoch 30/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - loss: 7458.9878 - mae: 7458.9878\n",
      "Epoch 31/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 7414.2461 - mae: 7414.2461\n",
      "Epoch 32/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 7368.5967 - mae: 7368.5967\n",
      "Epoch 33/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 7329.5205 - mae: 7329.5205\n",
      "Epoch 34/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - loss: 7293.5728 - mae: 7293.5728\n",
      "Epoch 35/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 7243.9780 - mae: 7243.9780\n",
      "Epoch 36/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 7202.9385 - mae: 7202.9385\n",
      "Epoch 37/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 7124.1479 - mae: 7124.1479\n",
      "Epoch 38/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 7070.9155 - mae: 7070.9155\n",
      "Epoch 39/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - loss: 7016.0737 - mae: 7016.0737\n",
      "Epoch 40/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - loss: 6965.2246 - mae: 6965.2246\n",
      "Epoch 41/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 6919.2554 - mae: 6919.2554\n",
      "Epoch 42/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6839.8955 - mae: 6839.8955\n",
      "Epoch 43/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - loss: 6776.7617 - mae: 6776.7617\n",
      "Epoch 44/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 6711.1260 - mae: 6711.1260\n",
      "Epoch 45/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6642.6689 - mae: 6642.6689\n",
      "Epoch 46/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 6571.2871 - mae: 6571.2871\n",
      "Epoch 47/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6496.8950 - mae: 6496.8950 \n",
      "Epoch 48/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 6418.8809 - mae: 6418.8809\n",
      "Epoch 49/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 6356.7896 - mae: 6356.7896\n",
      "Epoch 50/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 6264.4893 - mae: 6264.4893\n",
      "Epoch 51/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 6166.6880 - mae: 6166.6880\n",
      "Epoch 52/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 6069.0039 - mae: 6069.0039\n",
      "Epoch 53/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - loss: 5970.7095 - mae: 5970.7095\n",
      "Epoch 54/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 5867.7183 - mae: 5867.7183\n",
      "Epoch 55/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 5759.7495 - mae: 5759.7495\n",
      "Epoch 56/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - loss: 5664.2974 - mae: 5664.2974\n",
      "Epoch 57/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 5528.1133 - mae: 5528.1133\n",
      "Epoch 58/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 5419.1797 - mae: 5419.1797\n",
      "Epoch 59/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 5285.2236 - mae: 5285.2236\n",
      "Epoch 60/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 5159.1533 - mae: 5159.1533\n",
      "Epoch 61/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 5031.9902 - mae: 5031.9902\n",
      "Epoch 62/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - loss: 4900.4609 - mae: 4900.4609\n",
      "Epoch 63/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 4782.9180 - mae: 4782.9180\n",
      "Epoch 64/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 4635.2344 - mae: 4635.2344\n",
      "Epoch 65/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 584us/step - loss: 4513.8540 - mae: 4513.8540\n",
      "Epoch 66/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 4385.8965 - mae: 4385.8965\n",
      "Epoch 67/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 4275.4868 - mae: 4275.4868\n",
      "Epoch 68/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 4173.5381 - mae: 4173.5381\n",
      "Epoch 69/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 4079.2803 - mae: 4079.2803\n",
      "Epoch 70/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 3993.7378 - mae: 3993.7378\n",
      "Epoch 71/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - loss: 3915.6438 - mae: 3915.6438\n",
      "Epoch 72/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - loss: 3845.0085 - mae: 3845.0085\n",
      "Epoch 73/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 3788.3369 - mae: 3788.3369\n",
      "Epoch 74/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 3740.8667 - mae: 3740.8667\n",
      "Epoch 75/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 3704.0698 - mae: 3704.0698\n",
      "Epoch 76/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - loss: 3678.4409 - mae: 3678.4409\n",
      "Epoch 77/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 3659.7705 - mae: 3659.7705\n",
      "Epoch 78/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 3673.1282 - mae: 3673.1282\n",
      "Epoch 79/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - loss: 3638.8357 - mae: 3638.8357\n",
      "Epoch 80/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 3633.4829 - mae: 3633.4829\n",
      "Epoch 81/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 3645.6614 - mae: 3645.6614\n",
      "Epoch 82/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 3634.7917 - mae: 3634.7917\n",
      "Epoch 83/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step - loss: 3624.5186 - mae: 3624.5186\n",
      "Epoch 84/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 3623.4578 - mae: 3623.4578\n",
      "Epoch 85/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - loss: 3622.1934 - mae: 3622.1934\n",
      "Epoch 86/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 3635.4072 - mae: 3635.4072\n",
      "Epoch 87/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 3620.1641 - mae: 3620.1641\n",
      "Epoch 88/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 3619.0510 - mae: 3619.0510\n",
      "Epoch 89/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - loss: 3618.2188 - mae: 3618.2188\n",
      "Epoch 90/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 3617.4617 - mae: 3617.4617\n",
      "Epoch 91/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 3616.7415 - mae: 3616.7415\n",
      "Epoch 92/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 3615.9080 - mae: 3615.9080\n",
      "Epoch 93/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 3615.4419 - mae: 3615.4419\n",
      "Epoch 94/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 3614.1460 - mae: 3614.1460\n",
      "Epoch 95/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 3608.8831 - mae: 3608.8831\n",
      "Epoch 96/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - loss: 3610.3855 - mae: 3610.3855\n",
      "Epoch 97/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 3611.5649 - mae: 3611.5649\n",
      "Epoch 98/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 3624.5042 - mae: 3624.5042\n",
      "Epoch 99/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - loss: 3616.1768 - mae: 3616.1768\n",
      "Epoch 100/100\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 3605.3850 - mae: 3605.3850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70cbd504c080>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a neural network model to fit on our normalized data\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "insurance_model_4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(100),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(1)                                        \n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
    "                          optimizer=tf.keras.optimizers.Adam(),\n",
    "                          metrics=[\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "insurance_model_4.fit(X_train_normal, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wt84g6C790Y0",
    "outputId": "033111e9-a711-43de-c12d-8b816c66ca38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3515.8953 - mae: 3515.8953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3429.935791015625, 3429.935791015625]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalaute our insurance model trained on normalized data\n",
    "insurance_model_4.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDJuv8gB-IJ0"
   },
   "outputs": [],
   "source": [
    "# Insurance model 2 results\n",
    "# 9/9 [==============================] - 0s 1ms/step - loss: 4924.3477 - mae: 4924.3477"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZZQN7Z5_N46"
   },
   "source": [
    "Our model (`insurance_model_4`) fit on normalized data achieved a ~30% better score compared to the same model (`insurnace_model_2`) fit on non-normalized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ck80C5Im9Qo8",
    "outputId": "29d27eb2-7b2a-4141-c408-8b606a797a9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m1,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,665</span> (26.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,665\u001b[0m (26.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,221</span> (8.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,221\u001b[0m (8.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,444</span> (17.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,444\u001b[0m (17.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insurance_model_2.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO9X6tsDdr0vh0JARCmu1Ed",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1fZHXMZ5JpuadZknnJ93xFTkxUWnrLQt2",
   "name": "01_neural_network_regression_in_tensorflow_video.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
